{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "american-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exotic-messenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Images\n",
      "Name: robert\tEmail:robertDowney202@gmail.com\n",
      "\t download (2).jpg\n",
      "\t download (3).jpg\n",
      "\t download (4).jpg\n",
      "\t download (5).jpg\n",
      "\t download (6).jpg\n",
      "\t download.jpg\n",
      "\t images (1).jpg\n",
      "\t images (2).jpg\n",
      "\t images.jpg\n",
      "Name: tom\tEmail:Tomholand1@gmail.com\n",
      "\t download (1).jpg\n",
      "\t download (2).jpg\n",
      "\t download.jpg\n",
      "\t image.jpg\n",
      "\t images (1).jpg\n",
      "\t images (2).jpg\n",
      "\t images (3).jpg\n",
      "\t images.jpg\n",
      "\t tom-holland-photo-jason-kempin-getty-images-801510482-profile.jpg\n",
      "\t Tom_Holland_by_Gage_Skidmore.jpg\n"
     ]
    }
   ],
   "source": [
    "print(\"All the Images\")\n",
    "for i in os.listdir(\"../Storage\"):\n",
    "    print(\"Name: {}\\tEmail:{}\".format(i[0:i.find(\"_\")], i[i.find(\"_\")+1:]))\n",
    "    ctName = 0\n",
    "    for j in os.listdir(\"../Storage/\" + i):\n",
    "        print(\"\\t\",j)\n",
    "        #os.rename(\"../Storage/\" + i + \"/\" + j,\"Img_\"+ str(0) +\".jpg\")\n",
    "        #Instead of renaming create new folder within it and duplicate Images there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "considered-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "imgPath = \"../Storage/tom_Tomholand1@gmail.com/image.jpg\"\n",
    "im = Image.open(imgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fuzzy-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "requested-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectName = \"/\" + name + \"_\" + email + \"/\" + <FILE NAME.jpg>\n",
    "source = <FILE NAME.jpg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "charming-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "def list_blobs(bucket_name):\n",
    "    storage_client = storage.Client.from_service_account_json(key)\n",
    "    blobs = storage_client.list_blobs(bucket_name)\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "def list_buckets():\n",
    "    storage_client = storage.Client.from_service_account_json(key)\n",
    "    buckets = storage_client.list_buckets()\n",
    "    for bucket in buckets:\n",
    "        print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exotic-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEYDownloadedName = \"key.json\"\n",
    "#bucket = storage_client.bucket(\"loginly_storage\")\n",
    "#blob = bucket.get_blob(\"GCPKEY/loginly.json\")\n",
    "#blob.download_to_filename(KEYDownloadedName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regional-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "key = \"../GCPKEY/loginly.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "retired-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_1.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_10.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_2.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_3.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_4.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_5.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_6.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_7.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_8.jpg\n",
      "2021_2021@HAPPYNEWYEAR.COM/Img_NEW_9.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_1.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_10.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_2.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_3.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_4.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_5.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_6.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_7.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_8.jpg\n",
      "22hourshere_email@email.tld/Img_NEW_9.jpg\n",
      "asd_musk@tesla.com/Img_NEW_1.jpg\n",
      "asd_musk@tesla.com/Img_NEW_10.jpg\n",
      "asd_musk@tesla.com/Img_NEW_2.jpg\n",
      "asd_musk@tesla.com/Img_NEW_3.jpg\n",
      "asd_musk@tesla.com/Img_NEW_4.jpg\n",
      "asd_musk@tesla.com/Img_NEW_5.jpg\n",
      "asd_musk@tesla.com/Img_NEW_6.jpg\n",
      "asd_musk@tesla.com/Img_NEW_7.jpg\n",
      "asd_musk@tesla.com/Img_NEW_8.jpg\n",
      "asd_musk@tesla.com/Img_NEW_9.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_1.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_10.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_2.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_3.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_4.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_5.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_6.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_7.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_8.jpg\n",
      "chanem_musk@tesla.com/Img_NEW_9.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_1.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_2.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_3.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_4.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_5.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_6.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_7.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_8.jpg\n",
      "robert_robertDowney202@gmail.com/Img_NEW_9.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_1.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_10.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_2.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_3.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_4.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_5.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_6.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_7.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_8.jpg\n",
      "sorry_musk@tesla.com/Img_NEW_9.jpg\n"
     ]
    }
   ],
   "source": [
    "storage_client = storage.Client.from_service_account_json(key) #\"key.json\"\n",
    "bucket_name = 'loginly_storage'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "mainDir = os.getcwd()\n",
    "#os.mkdir(\"/tmp/dataset/\")\n",
    "#os.chdir(\"/tmp/dataset/\")\n",
    "for blob in blobs:\n",
    "    if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "        #blob.download_to_filename(blob.name)\n",
    "        print(blob.name[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mineral-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"CleanData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-wings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-honolulu",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to take in the 10 image names and the user's email and user's \n",
    "# name and crops the image and upload to proper folder in GCP \n",
    "#-----\n",
    "# INPUT:   IMG1, IMG2, IMG3 ... IMG10, NAME, EMAIL\n",
    "#--------------\n",
    "key = \"../GCPKEY/loginly.json\"\n",
    "harascade = '../Models/haarcascades/haarcascade_frontalface_alt2.xml'\n",
    "# key.json                              file on function      \n",
    "# haarcascade_frontalface_alt2.xml      file on function \n",
    "#--------------\n",
    "# INPUT NEEDS FOR THE FUNCTION TO CLEAN THE DATA\n",
    "#fileName0 = \n",
    "name = \"robert\"\n",
    "email = \"robertDowney202@gmail.com\"\n",
    "folder = name + \"_\" + email\n",
    "#?img1=download (2).jpg&img2=download (3).jpg&img3=download (4).jpg&img4=download (5).jpg&img5=download (6).jpg&img6=download.jpg\n",
    "#&img7=images (1).jpg&img8=images (2).jpg&img9=images.jpg&img10=test.jpg&name=robert&email=robertDowney202@gmail.com\n",
    "fileName1 = \"download (2).jpg\"\n",
    "fileName2 = \"download (3).jpg\"\n",
    "fileName3 = \"download (4).jpg\"\n",
    "fileName4 = \"download (5).jpg\"\n",
    "fileName5 = \"download (6).jpg\"\n",
    "fileName6 = \"download.jpg\"\n",
    "fileName7 = \"images (1).jpg\"\n",
    "fileName8 = \"images (2).jpg\"\n",
    "fileName9 = \"images.jpg\"\n",
    "lstOfFiles = [fileName1,fileName2,fileName3,fileName4,fileName5,fileName6,fileName7,fileName8,fileName9]\n",
    "#-------------\n",
    "# DOWNLOADS THE FILES FROM GCP FUNCTION\n",
    "os.chdir(\"/Users/kunal/Documents/AAPersonalAIPROJECT/LOGINLY/Code\") # Comment later\n",
    "storage_client = storage.Client.from_service_account_json(key) #\"key.json\"\n",
    "bucket_name = 'loginly_storage'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "ctFileName = 1\n",
    "for i in lstOfFiles:\n",
    "    blob = bucket.blob(\"Storage/\"+folder+\"/\" + i)\n",
    "    blob.download_to_filename(\"Img_org_\" + str(ctFileName) + \".jpg\")\n",
    "    ctFileName+=1\n",
    "#--------------\n",
    "# FILE NAMES \n",
    "downloadedFilesName = []\n",
    "for i in range(len(lstOfFiles)):\n",
    "    downloadedFilesName.append(\"Img_org_\" + str(i+1) + \".jpg\")\n",
    "#-------------\n",
    "# CONVERT TO GRAYSCALE IMAGES WITH SCALED ON IMAGE \n",
    "os.mkdir(folder + \"_CLEAN\")\n",
    "ctFileNameNew = 1\n",
    "newFilesName = []\n",
    "for i in downloadedFilesName:\n",
    "    img = cv2.imread(i)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(harascade)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    #1.1: scale factor, it specifies how much the image size is reduced with each scale. It improves detection.\n",
    "    #4: MinNeighbours, specifies how many neighbors each candidate rectangle should have to retain.\n",
    "    if len(faces) > 0:\n",
    "        x,y,w,h = faces[0]\n",
    "    else:\n",
    "        x,y = 0,0\n",
    "        w,h = img.shape[0:2]\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    currentDir = os.getcwd()\n",
    "    os.chdir(folder + \"_CLEAN\")\n",
    "    cv2.imwrite(\"Img_NEW_\" + str(ctFileNameNew) + \".jpg\", crop_img)\n",
    "    os.chdir(currentDir)\n",
    "    newFilesName.append(\"Img_NEW_\" + str(ctFileNameNew) + \".jpg\")\n",
    "    ctFileNameNew+=1\n",
    "#-------------- \n",
    "#upload new files\n",
    "os.chdir(folder + \"_CLEAN\")\n",
    "for i in newFilesName:\n",
    "    blob = bucket.blob(\"CleanData/\" +folder+\"/\"+ i)\n",
    "    blob.upload_from_filename(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "registered-beatles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CleanData/\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_1.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_10.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_2.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_3.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_4.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_5.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_6.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_7.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_8.jpg\n",
      "CleanData/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_9.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_1.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_10.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_2.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_3.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_4.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_5.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_6.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_7.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_8.jpg\n",
      "CleanData/asd_musk@tesla.com/Img_NEW_9.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_1.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_10.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_2.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_3.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_4.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_5.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_6.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_7.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_8.jpg\n",
      "CleanData/chanem_musk@tesla.com/Img_NEW_9.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_1.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_2.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_3.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_4.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_5.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_6.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_7.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_8.jpg\n",
      "CleanData/robert_robertDowney202@gmail.com/Img_NEW_9.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_1.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_10.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_2.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_3.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_4.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_5.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_6.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_7.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_8.jpg\n",
      "CleanData/sorry_musk@tesla.com/Img_NEW_9.jpg\n",
      "GCPKEY/loginly.json\n",
      "GCPKEY/uploadImg.json\n",
      "LiveModel\n",
      "LiveModel/\n",
      "Models/encodings/face_training_encodings.pkl\n",
      "Models/encodings/jpark.pkl\n",
      "Models/haarcascades/haarcascade_eye.xml\n",
      "Models/haarcascades/haarcascade_eye_tree_eyeglasses.xml\n",
      "Models/haarcascades/haarcascade_frontalcatface.xml\n",
      "Models/haarcascades/haarcascade_frontalcatface_extended.xml\n",
      "Models/haarcascades/haarcascade_frontalface_alt.xml\n",
      "Models/haarcascades/haarcascade_frontalface_alt2.xml\n",
      "Models/haarcascades/haarcascade_frontalface_alt_tree.xml\n",
      "Models/haarcascades/haarcascade_frontalface_default.xml\n",
      "Models/haarcascades/haarcascade_fullbody.xml\n",
      "Models/haarcascades/haarcascade_lefteye_2splits.xml\n",
      "Models/haarcascades/haarcascade_licence_plate_rus_16stages.xml\n",
      "Models/haarcascades/haarcascade_lowerbody.xml\n",
      "Models/haarcascades/haarcascade_profileface.xml\n",
      "Models/haarcascades/haarcascade_righteye_2splits.xml\n",
      "Models/haarcascades/haarcascade_russian_plate_number.xml\n",
      "Models/haarcascades/haarcascade_smile.xml\n",
      "Models/haarcascades/haarcascade_upperbody.xml\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (1).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (10).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (2).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (3).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (4).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (5).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (6).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (7).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (8).jpg\n",
      "Storage/2021_2021@HAPPYNEWYEAR.COM/image (9).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (10).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (2).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (3).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (4).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (5).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (6).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (7).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (8).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga (9).jpg\n",
      "Storage/ElonL_musk@tesla.com/descarga.jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (10).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (2).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (3).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (4).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (5).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (6).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (7).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (8).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga (9).jpg\n",
      "Storage/Elon_musk@tesla.com/descarga.jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (1).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (10).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (2).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (3).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (4).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (5).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (6).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (7).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (8).jpg\n",
      "Storage/Hack_limusina10@gmail.com/image (9).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (1).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (10).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (2).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (3).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (4).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (5).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (6).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (7).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (8).jpg\n",
      "Storage/Jaum_limusina10@gmail.com/image (9).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (1).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (10).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (2).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (3).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (4).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (5).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (6).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (7).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (8).jpg\n",
      "Storage/Jaume_limusina10@gmail.com/image (9).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (1).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (10).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (2).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (3).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (4).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (5).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (6).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (7).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (8).jpg\n",
      "Storage/Kunal_limusina@email.tld/image (9).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (10).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (2).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (3).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (4).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (5).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (6).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (7).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (8).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga (9).jpg\n",
      "Storage/Muskk_musk@tesla.com/descarga.jpg\n",
      "Storage/asd_musk@tesla.com/descarga (10).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (2).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (3).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (4).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (5).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (6).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (7).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (8).jpg\n",
      "Storage/asd_musk@tesla.com/descarga (9).jpg\n",
      "Storage/asd_musk@tesla.com/descarga.jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (10).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (2).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (3).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (4).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (5).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (6).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (7).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (8).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga (9).jpg\n",
      "Storage/chanem_musk@tesla.com/descarga.jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (10).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (2).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (3).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (4).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (5).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (6).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (7).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (8).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga (9).jpg\n",
      "Storage/comeon_musk@tesla.com/descarga.jpg\n",
      "Storage/milion_musk@tesla.com/descarga (10).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (2).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (3).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (4).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (5).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (6).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (7).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (8).jpg\n",
      "Storage/milion_musk@tesla.com/descarga (9).jpg\n",
      "Storage/milion_musk@tesla.com/descarga.jpg\n",
      "Storage/robert_robertDowney202@gmail.com/download (2).jpg\n",
      "Storage/robert_robertDowney202@gmail.com/download (3).jpg\n",
      "Storage/robert_robertDowney202@gmail.com/download (4).jpg\n",
      "Storage/robert_robertDowney202@gmail.com/download (5).jpg\n",
      "Storage/robert_robertDowney202@gmail.com/download (6).jpg\n",
      "Storage/robert_robertDowney202@gmail.com/download.jpg\n",
      "Storage/robert_robertDowney202@gmail.com/images (1).jpg\n",
      "Storage/robert_robertDowney202@gmail.com/images (2).jpg\n",
      "Storage/robert_robertDowney202@gmail.com/images.jpg\n",
      "Storage/robert_robertDowney202@gmail.com/test.jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (10).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (2).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (3).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (4).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (5).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (6).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (7).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (8).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga (9).jpg\n",
      "Storage/sorry_musk@tesla.com/descarga.jpg\n",
      "Storage/testImg_test@gmail.com/a.jpg\n",
      "Storage/tom_Tomholand1@gmail.com/Tom_Holland_by_Gage_Skidmore.jpg\n",
      "Storage/tom_Tomholand1@gmail.com/download (1).jpg\n",
      "Storage/tom_Tomholand1@gmail.com/download (2).jpg\n",
      "Storage/tom_Tomholand1@gmail.com/download.jpg\n",
      "Storage/tom_Tomholand1@gmail.com/image.jpg\n",
      "Storage/tom_Tomholand1@gmail.com/images (1).jpg\n",
      "Storage/tom_Tomholand1@gmail.com/images (2).jpg\n",
      "Storage/tom_Tomholand1@gmail.com/images (3).jpg\n",
      "Storage/tom_Tomholand1@gmail.com/images.jpg\n",
      "Storage/tom_Tomholand1@gmail.com/tom-holland-photo-jason-kempin-getty-images-801510482-profile.jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (10).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (2).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (3).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (4).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (5).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (6).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (7).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (8).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga (9).jpg\n",
      "Storage/twenty_musk@tesla.com/descarga.jpg\n"
     ]
    }
   ],
   "source": [
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "for blob in blobs:\n",
    "    #if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "        #blob.download_to_filename(blob.name)\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adapted-deposit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'OpenCV-Face-Recognition-Python.ipynb',\n",
       " 'pickel.pkl',\n",
       " 'robert_robertDowney202@gmail.com_CLEAN',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assured-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from imutils import paths\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-ethnic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alert-worcester",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/pickel.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-061dd7401d6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Models/encodings/jpark.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_to_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/tmp/pickel.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#---------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mblobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_blobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kunal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\google\\cloud\\storage\\blob.py\u001b[0m in \u001b[0;36mdownload_to_filename\u001b[1;34m(self, filename, client, start, end, raw_download, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_require_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                 client.download_blob_to_file(\n\u001b[0;32m   1215\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/pickel.pkl'"
     ]
    }
   ],
   "source": [
    "storage_client = storage.Client.from_service_account_json(key) #\"key.json\"\n",
    "bucket_name = 'loginly_storage'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(\"Models/encodings/jpark.pkl\")\n",
    "blob.download_to_filename(\"/tmp/pickel.pkl\")\n",
    "#---------------------\n",
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "os.mkdir(\"/tmp/dataset/\")\n",
    "os.chdir(\"/tmp/dataset/\")\n",
    "for blob in blobs:\n",
    "    if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "        #blob.download_to_filename(blob.name)\n",
    "        print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/tmp/dataset/\"\n",
    "imagePaths = list(paths.list_images(dataset))\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "detection_method = \"cnn\"\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the person name from the image path\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    #print(f\"[INFO] processing image [{name}] {i+1}/{len(imagePaths)}\")\n",
    "    # load the input image and convert from BGR to RGB for dlib\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # detect the (x,y)-coordinates of the bounding boxes\n",
    "    # corresponding to each face in the input image\n",
    "    # we are assuming the the boxes of faces are the SAME FACE or SAME PERSON\n",
    "    boxes = face_recognition.face_locations(rgb_image, model=detection_method)\n",
    "    # compute the facial embedding for the face\n",
    "    # creates a vector of 128 numbers representing the face\n",
    "    encodings = face_recognition.face_encodings(rgb_image, boxes)\n",
    "    # loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        # add each encoding + name to our set of known names and encodings\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "encodings_file = \"/tmp/pickel.pkl\"\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "f = open(encodings_file, \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()\n",
    "#---------------------hope this works\n",
    "#UPLOAD FILE\n",
    "bucket_name = 'loginly_storage'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(\"LiveModel/pickel.pkl\")\n",
    "blob.upload_from_filename(\"pickel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "surprised-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(\"LiveModel/\")\n",
    "blob.upload_from_filename(\"pickel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "numerical-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(\"/LiveModel\")\n",
    "blob.upload_from_filename(\"pickel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spread-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'loginly_storage'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(\"LiveModel/pickel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "separated-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.upload_from_filename(\"pickel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client.from_service_account_json(key) #\"key.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "gothic-swift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Blob: loginly_storage, LiveModel/, None>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mature-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = \"../TestImg/test.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continuous-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading encodings...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(encodings_file, \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "previous-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image and convert it from BGR to RGB\n",
    "image = cv2.imread(input_image)\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cultural-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] recognize faces...\n"
     ]
    }
   ],
   "source": [
    "# detect the (x,y)-coordinates of the bounding boxes cooresponding to each\n",
    "# face in the input image, then compute the facial embeddings for each face\n",
    "print(\"[INFO] recognize faces...\")\n",
    "boxes = face_recognition.face_locations(rgb_image, model=detection_method)\n",
    "encodings = face_recognition.face_encodings(rgb_image, boxes)\n",
    "\n",
    "# initialize the list of names for each face detected\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "affecting-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the facial embeddings\n",
    "for encoding in encodings:\n",
    "    # attempt to match each face in the input to our known encodings\n",
    "    # This function returns a list of True / False  values, one for each image in our dataset.\n",
    "    # since the dataset has 218 Jurassic Park images, len(matches)=218\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # check to see if we have found any matches\n",
    "    if True in matches:\n",
    "        # find the indexes of all matched faces then initialize a dictionary to count\n",
    "        # the total number of times each face was matched\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "\n",
    "        # loop over the matched indexes and maintain a count for each recognized face face\n",
    "        for i in matchedIdxs:\n",
    "            name = data['names'][i]\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "        # determine the recognized face with the largest number of votes: (notes: in the event of an unlikely\n",
    "        # tie, Python will select first entry in the dictionary)\n",
    "        name = max(counts, key=counts.get)\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interested-louisiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over the recognized faces\n",
    "for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "    # draw the predicted face name on the image\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "    y = top - 15 if top - 15 > 15 else top + 15\n",
    "    cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.75, (0, 255, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-scottish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "furnished-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "contained-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgPath = \"../Storage/tom_Tomholand1@gmail.com/image.jpg\"\n",
    "a =cv2.imread(imgPath)\n",
    "ts = a.tobytes()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "remarkable-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"/Users/kunal/Documents/AAPersonalAIPROJECT/LOGINLY/GCPKEY/loginly.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sonic-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client.from_service_account_json(key) #\"key.json\"\n",
    "bucket_name = 'loginly_storage'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "#--------------------------------------------------\n",
    "mainDir = os.getcwd()\n",
    "#os.makedirs(\"/tmp/dataset\")\n",
    "#---------------------------\n",
    "lst = []\n",
    "for blob in blobs:\n",
    "    if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "        lst.append(blob.name[10:blob.name[10:].find(\"/\")+10])\n",
    "        #lst.append(blob.name[10:].replace(\"/\", \"-*-\"))\n",
    "        #blob.download_to_filename(blob.name[10:].replace(\"/\", \"-*-\"))\n",
    "        #os.chdir(\"/tmp/dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-sally",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "consecutive-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesNum = list(set(lst))\n",
    "titlesNumInt = []\n",
    "for i in range(len(titlesNum)):\n",
    "    titlesNumInt.append([titlesNum[i] , i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "close-strengthening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['chanem_musk@tesla.com', 1],\n",
       " ['sorry_musk@tesla.com', 2],\n",
       " ['robert_robertDowney202@gmail.com', 3],\n",
       " ['asd_musk@tesla.com', 4],\n",
       " ['22hourshere_email@email.tld', 5],\n",
       " ['2021_2021@HAPPYNEWYEAR.COM', 6],\n",
       " ['asdasd_elon@musk.com', 7]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlesNumInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_world(request):\n",
    "    \"\"\"Responds to any HTTP request.\n",
    "    Args:\n",
    "        request (flask.Request): HTTP request object.\n",
    "    Returns:\n",
    "        The response text or any set of values that can be turned into a\n",
    "        Response object using\n",
    "        `make_response <http://flask.pocoo.org/docs/1.0/api/#flask.Flask.make_response>`.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    import numpy as np\n",
    "    request_json = request.get_json()\n",
    "    if request.args and 'train' in request.args:\n",
    "        if request.args.get('train') == \"RUN\":\n",
    "            storage_client = storage.Client.from_service_account_json(\"key.json\") #\"key.json\"\n",
    "            bucket_name = 'loginly_storage'\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blobs = storage_client.list_blobs(bucket_name)\n",
    "            #--------------------------------------------------\n",
    "            mainDir = os.getcwd()\n",
    "            #os.remove(\"/tmp\")\n",
    "            os.makedirs(\"/tmp/dataset\")\n",
    "            os.chdir(\"/tmp/dataset\")\n",
    "            #---------------------------\n",
    "            #foldersCreated = []\n",
    "            #for blob in blobs:\n",
    "            #    if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "            #        folderNameTemp = blob.name[10:blob.name[10:].find(\"/\")+10]\n",
    "            #        if not folderNameTemp in foldersCreated:\n",
    "            #            os.mkdir(folderNameTemp)\n",
    "            #            foldersCreated.append(folderNameTemp)\n",
    "            #---------------------------\n",
    "            titleNames = []\n",
    "            for blob in blobs:\n",
    "                if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "                    #os.chdir(blob.name[10:blob.name[10:].find(\"/\")+10])\n",
    "                    blob.download_to_filename(blob.name[10:].replace(\"/\", \"-*-\"))\n",
    "                    #print(blob.name[10:])\n",
    "                    #os.chdir(\"/tmp/dataset\")\n",
    "                    titleNames.append(blob.name[10:blob.name[10:].find(\"/\")+10])\n",
    "            dataset = \"/tmp/dataset/\"\n",
    "            \n",
    "            titleNamesNew = list(set(titleNames))\n",
    "            stringReturnTest = \"\"\n",
    "            for i in titleNamesNew:\n",
    "                stringReturnTest+=i + \"; \"\n",
    "            return stringReturnTest #TEST HERE FOR \n",
    "\n",
    "            \n",
    "            titlesNumInt = []\n",
    "            for i in range(len(titleNamesNew)):\n",
    "                titlesNumInt.append([titlesNum[i] , i+1])\n",
    "            \n",
    "            os.chdir(mainDir)\n",
    "            dirs = os.listdir(dataset)\n",
    "            faces = []\n",
    "            labels = []\n",
    "            labelsInt = []\n",
    "            ct=1\n",
    "            for dir_name in dirs:\n",
    "                if dir_name.startswith(\".\"):\n",
    "                    continue\n",
    "                label = dir_name[:dir_name.find(\"-*-\")]\n",
    "                \"\"\"label = dir_name\n",
    "                for image_name in os.listdir(dir_name):\n",
    "                    if image_name.startswith(\".\"):\n",
    "                        continue;\"\"\"\n",
    "                image_path = \"/tmp/dataset/\" + dir_name\n",
    "                image = cv2.imread(image_path)\n",
    "                face, rect = detect_face(image)\n",
    "                if face is not None:\n",
    "                    faces.append(face)\n",
    "                    labels.append(label)\n",
    "                    for i in titlesNumInt:\n",
    "                        if i[0] == label:\n",
    "                            labelsInt.append(i[1])\n",
    "                ct+=1\n",
    "            \n",
    "            face_recognizer = cv2.face.LBPHFaceRecognizer_create() \n",
    "            face_recognizer.train(faces, np.array(labels))\n",
    "\n",
    "            face_recognizer.write(\"MODEL.yml\")\n",
    "\n",
    "            bucket_name = 'loginly_storage'\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(\"LiveModel/MODEL.yml\")\n",
    "            blob.upload_from_filename(\"MODEL.yml\")\n",
    "            return \"COMPLETED\"\n",
    "            \"\"\"\n",
    "        else:\n",
    "            return \"TOLD NOT TO RUN\"\n",
    "\n",
    "\n",
    "\n",
    "    elif request_json and 'message' in request_json:\n",
    "        return request_json['message']\n",
    "    else:\n",
    "        return f'Hello World!'\n",
    "\n",
    "\n",
    "#function to detect face using OpenCV\n",
    "def detect_face(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    (x, y, w, h) = faces[0]\n",
    "    return gray[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in blobs:\n",
    "                if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "                    #os.chdir(blob.name[10:blob.name[10:].find(\"/\")+10])\n",
    "                    blob.download_to_filename(blob.name[10:].replace(\"/\", \"-*-\"))\n",
    "                    #print(blob.name[10:])\n",
    "                    #os.chdir(\"/tmp/dataset\")\n",
    "\n",
    "            dataset = \"/tmp/dataset/\"\n",
    "            titleNames = []\n",
    "            for i in os.listdir(dataset):\n",
    "                titleNames.append(i)\n",
    "            \n",
    "            stringReturnTest = \"\"\n",
    "            for i in titleNames:\n",
    "                stringReturnTest+=i + \"; \"\n",
    "            return stringReturnTest #TEST HERE FOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "existing-province",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-906bc53a5875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CleanData/\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"CleanData/\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_to_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;31m#print(blob.name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/tmp/dataset/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kunal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\google\\cloud\\storage\\blob.py\u001b[0m in \u001b[0;36mdownload_to_filename\u001b[1;34m(self, filename, client, start, end, raw_download, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_require_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                 client.download_blob_to_file(\n\u001b[0;32m   1215\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/2021_2021@HAPPYNEWYEAR.COM/Img_NEW_1.jpg'"
     ]
    }
   ],
   "source": [
    "mainDir = os.getcwd()\n",
    "os.mkdir(\"dataset/\")\n",
    "os.chdir(\"dataset/\")\n",
    "for blob in blobs:\n",
    "    if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "        \n",
    "        #blob.download_to_filename(\"dataset/\" + blob.name[10:])\n",
    "        print(blob.name)\n",
    "dataset = \"/tmp/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excess-dividend",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Iterator has already started', <google.api_core.page_iterator.HTTPIterator object at 0x000001907E33AE20>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4974f181bcd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CleanData/\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"CleanData/\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m#blob.download_to_filename(\"dataset/\" + blob.name[10:])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kunal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\google\\api_core\\page_iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iterator has already started\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Iterator has already started', <google.api_core.page_iterator.HTTPIterator object at 0x000001907E33AE20>)"
     ]
    }
   ],
   "source": [
    "for blob in blobs:\n",
    "    if blob.name.startswith(\"CleanData/\") and not blob.name == \"CleanData/\":\n",
    "        \n",
    "        #blob.download_to_filename(\"dataset/\" + blob.name[10:])\n",
    "        print(blob.name)\n",
    "dataset = \"/tmp/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dominican-footwear",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'createLBPHFaceRecognizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-dd98c70ef76e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecognizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateLBPHFaceRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'createLBPHFaceRecognizer'"
     ]
    }
   ],
   "source": [
    "recognizer = cv2.createLBPHFaceRecognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-guinea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-midnight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
